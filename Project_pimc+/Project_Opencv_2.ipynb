{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bitdl4cvvenv45c9af2e94a64bd899752ddc062498d9",
   "display_name": "Python 3.7.7 64-bit ('dl4cv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "def load_data(path):\n",
    "    loaded_data = loadmat(path)\n",
    "    return loaded_data['X'], loaded_data['y']\n",
    "\n",
    "X_train, Y_train = load_data('train_32x32.mat')\n",
    "X_test, Y_test = load_data('test_32x32.mat')\n",
    "X_train_original = X_train\n",
    "X_test_original = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the shape of the training and the test dataset\n",
    "X_train = X_train.transpose((3, 0, 1, 2))\n",
    "X_test = X_test.transpose((3, 0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 2-D array into 1-D array\n",
    "Y_train = Y_train[:,0]\n",
    "Y_test = Y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the label of 0 from 10 to 0\n",
    "Y_train[Y_train==10] = 0\n",
    "Y_test[Y_test==10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train\n",
    "Y_train_original = Y_train\n",
    "X_test_original = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the training set into training and validation set using sklearn\n",
    "#using random_state to generate the same sets everytime\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_original, Y_train_original, test_size=0.15, random_state=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting array of ints to array of floats for arithmetic operations\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb2grey = [0.2990, 0.5870, 0.1140]\n",
    "X_train = np.expand_dims(np.dot(X_train, rgb2grey), axis=3)\n",
    "X_val = np.expand_dims(np.dot(X_val, rgb2grey), axis=3)\n",
    "X_test = np.expand_dims(np.dot(X_test, rgb2grey), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising the training data for better training\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train_normalised = (X_train-train_mean)/train_std\n",
    "X_val_normalised = (X_val-train_mean)/train_std\n",
    "X_test_normalised = (X_test-train_mean)/train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='relu', input_shape=(32,32,1)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #compiling the model\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 62268 samples, validate on 10989 samples\nEpoch 1/20\n62268/62268 [==============================] - 147s 2ms/step - loss: 2.1329 - accuracy: 0.2615 - val_loss: 1.2492 - val_accuracy: 0.5911\nEpoch 2/20\n62268/62268 [==============================] - 134s 2ms/step - loss: 1.0903 - accuracy: 0.6556 - val_loss: 0.7528 - val_accuracy: 0.7701\nEpoch 3/20\n62268/62268 [==============================] - 126s 2ms/step - loss: 0.7815 - accuracy: 0.7616 - val_loss: 0.6625 - val_accuracy: 0.7944\nEpoch 4/20\n62268/62268 [==============================] - 132s 2ms/step - loss: 0.6964 - accuracy: 0.7875 - val_loss: 0.6160 - val_accuracy: 0.8114\nEpoch 5/20\n62268/62268 [==============================] - 136s 2ms/step - loss: 0.6306 - accuracy: 0.8085 - val_loss: 0.5652 - val_accuracy: 0.8298\nEpoch 6/20\n62268/62268 [==============================] - 135s 2ms/step - loss: 0.5874 - accuracy: 0.8229 - val_loss: 0.5436 - val_accuracy: 0.8337\nEpoch 7/20\n62268/62268 [==============================] - 120s 2ms/step - loss: 0.5451 - accuracy: 0.8361 - val_loss: 0.5261 - val_accuracy: 0.8451\nEpoch 8/20\n62268/62268 [==============================] - 138s 2ms/step - loss: 0.5158 - accuracy: 0.8442 - val_loss: 0.4789 - val_accuracy: 0.8578\nEpoch 9/20\n62268/62268 [==============================] - 137s 2ms/step - loss: 0.4886 - accuracy: 0.8518 - val_loss: 0.4639 - val_accuracy: 0.8610\nEpoch 10/20\n62268/62268 [==============================] - 136s 2ms/step - loss: 0.4664 - accuracy: 0.8595 - val_loss: 0.4630 - val_accuracy: 0.8622\nEpoch 11/20\n62268/62268 [==============================] - 140s 2ms/step - loss: 0.4439 - accuracy: 0.8653 - val_loss: 0.4565 - val_accuracy: 0.8630\nEpoch 12/20\n62268/62268 [==============================] - 154s 2ms/step - loss: 0.4321 - accuracy: 0.8694 - val_loss: 0.4483 - val_accuracy: 0.8669\nEpoch 13/20\n62268/62268 [==============================] - 151s 2ms/step - loss: 0.4069 - accuracy: 0.8776 - val_loss: 0.4448 - val_accuracy: 0.8669\nEpoch 14/20\n62268/62268 [==============================] - 130s 2ms/step - loss: 0.4000 - accuracy: 0.8790 - val_loss: 0.4224 - val_accuracy: 0.8776\nEpoch 15/20\n62268/62268 [==============================] - 150s 2ms/step - loss: 0.3871 - accuracy: 0.8841 - val_loss: 0.4570 - val_accuracy: 0.8662\nEpoch 16/20\n62268/62268 [==============================] - 148s 2ms/step - loss: 0.3831 - accuracy: 0.8842 - val_loss: 0.4242 - val_accuracy: 0.8758\nEpoch 17/20\n62268/62268 [==============================] - 143s 2ms/step - loss: 0.3675 - accuracy: 0.8872 - val_loss: 0.4378 - val_accuracy: 0.8758\nEpoch 18/20\n62268/62268 [==============================] - 143s 2ms/step - loss: 0.3564 - accuracy: 0.8919 - val_loss: 0.4497 - val_accuracy: 0.8685\nEpoch 19/20\n62268/62268 [==============================] - 143s 2ms/step - loss: 0.3501 - accuracy: 0.8951 - val_loss: 0.4335 - val_accuracy: 0.8804\nEpoch 20/20\n62268/62268 [==============================] - 148s 2ms/step - loss: 0.3393 - accuracy: 0.8959 - val_loss: 0.4280 - val_accuracy: 0.8751\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x15ab45c50>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=64, epochs=20, verbose=1, validation_data=(X_val,Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "26032/26032 [==============================] - 15s 587us/step\n"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('street_view_house_numbers_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Model\n",
    "from keras.models import load_model\n",
    "model = load_model('street_view_house_numbers_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[3]\n[[0.0000000e+00 5.3874797e-20 0.0000000e+00 6.7763740e-01 2.8107476e-35\n  3.2236263e-01 2.5433484e-37 2.6789318e-38 4.0331179e-17 1.7402039e-16]]\n"
    }
   ],
   "source": [
    "# make a prediction for a new image.\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, grayscale=True, target_size=(32, 32))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 1 channel\n",
    "\timg = img.reshape(1, 32, 32, 1)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\t#img = img / 255.0\n",
    "\treturn img\n",
    " \n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('5.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('street_view_house_numbers_model.h5')\n",
    "\t# predict the class\n",
    "\tdigit = model.predict_classes(img)\n",
    "\tprint(digit)\n",
    "\tdigit1 = model.predict(img)\n",
    "\tprint(digit1)\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10500 is out of bounds for axis 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-26cdf57bf478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 10500 is out of bounds for axis 0 with size 32"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[10500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('street_view_house_numbers_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = model.predict(X_test[949:952])\n",
    "test_x_predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.imshow(test_x_predictions)44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "def load_data(path): \n",
    "    loaded_data = loadmat(path)\n",
    "    return loaded_data['X'], loaded_data['y']\n",
    "\n",
    "X_train, Y_train = load_data('train_32x32.mat')\n",
    "X_test, Y_test = load_data('test_32x32.mat')\n",
    "X_train_original = X_train\n",
    "X_test_original = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the shape of the training and the test dataset\n",
    "X_train = X_train.transpose((3, 0, 1, 2))\n",
    "X_test = X_test.transpose((3, 0, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train[:,0]\n",
    "Y_test = Y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the label of 0 from 10 to 0\n",
    "Y_train[Y_train==10] = 0\n",
    "Y_test[Y_test==10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.imshow(X_train[10500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train\n",
    "Y_train_original = Y_train\n",
    "X_test_original = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the training set into training and validation set using sklearn\n",
    "#using random_state to generate the same sets everytime\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_original, Y_train_original, test_size=0.15, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting array of ints to array of floats for arithmetic operations\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.expand_dims(np.dot(X_train[0], rgb2grey), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test[:,:,0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting rgb images to grayscale images for faster computations\n",
    "rgb2grey = [0.2990, 0.5870, 0.1140]\n",
    "X_train = np.expand_dims(np.dot(X_train, rgb2grey), axis=3)\n",
    "X_val = np.expand_dims(np.dot(X_val, rgb2grey), axis=3)\n",
    "X_test = np.expand_dims(np.dot(X_test, rgb2grey), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising the training data for better training\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train_normalised = (X_train-train_mean)/train_std\n",
    "X_val_normalised = (X_val-train_mean)/train_std\n",
    "X_test_normalised = (X_test-train_mean)/train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}